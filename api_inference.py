import os
import json
import pandas as pd
import time
from openai import OpenAI
import concurrent.futures
from tqdm import tqdm

# --- ä¿®æ”¹å ---
if os.environ.get('GITHUB_ACTIONS') == 'true':
    print(">>> [ç¯å¢ƒæ£€æµ‹] GitHub Actions ç¯å¢ƒï¼šæ¸…é™¤ä»£ç†é…ç½®ã€‚")
    os.environ.pop("http_proxy", None)
    os.environ.pop("https_proxy", None)
else:
    # ä»…åœ¨æœ¬åœ°å¼€å‘ä¸”æ²¡åœ¨è„šæœ¬å¤–è®¾ç½®ä»£ç†æ—¶æ‰æ‰‹åŠ¨æŒ‡å®š
    os.environ['http_proxy'] = 'http://127.0.0.1:7897'
    os.environ['https_proxy'] = 'http://127.0.0.1:7897'

# ================= é…ç½®åŒºåŸŸ =================

# --- ä¿®æ”¹å ---
# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœè¯»å–ä¸åˆ°ï¼ˆæœ¬åœ°è°ƒè¯•ï¼‰å†ä½¿ç”¨é»˜è®¤å€¼ï¼ˆä¸æ¨èï¼Œå»ºè®®æœ¬åœ°ä¹Ÿè®¾ç¯å¢ƒå˜é‡ï¼‰
API_BASE = os.environ.get("OPENAI_API_BASE", "http://35.220.164.252:3888/v1/")
API_KEY = os.environ.get("OPENAI_API_KEY")

if not API_KEY:
    print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚")
    # å¦‚æœæ˜¯æœ¬åœ°è¿è¡Œï¼Œå¯ä»¥åœ¨è¿™é‡Œä¸´æ—¶å†™ä¸€ä¸ªå¤‡ç”¨ Keyï¼Œä½†ä¸Šä¼ å‰åŠ¡å¿…åˆ é™¤
    # API_KEY = "sk-xxxx"

# æ¨¡å‹é€‰æ‹©ï¼šæ€§ä»·æ¯”ä¹‹é€‰
MODEL_NAME = "gpt-4o-mini"

# å¹¶å‘æ•° (APIé€šå¸¸æ”¯æŒé«˜å¹¶å‘ï¼Œå»ºè®® 20-50)
MAX_WORKERS = 50

# è¾“å…¥è¾“å‡º
INPUT_FILE = "raw_papers.json"
OUTPUT_FILE = "daily_papers.json"
SCHOOL_CSV = "é«˜æ ¡.csv"
COMPANY_CSV = "å…¬å¸.csv"

# è®¾ç½®ä¸€ä¸ªå…¨å±€è°ƒè¯•å¼€å…³
DEBUG_SAVE_ABSTRACT = True
DEBUG_MODE = True

# ================= 1. æ•°æ®åŠ è½½ä¸è§„åˆ™æ„å»º (å¤ç”¨é€»è¾‘) =================

class DataManager:
    def __init__(self):
        self.inst_map = {}  # å…³é”®è¯ -> {æ ‡å‡†å, ç±»å‹}
        self.person_rules = set()  # å¤§ç‰›åå•
        self.load_rules()

    def load_rules(self):
        print("ğŸ“Š [Init] æ­£åœ¨åŠ è½½æœºæ„ä¸äººå‘˜è§„åˆ™...")
        # 1. åŠ è½½é«˜æ ¡
        try:
            if os.path.exists(SCHOOL_CSV):
                df_school = pd.read_csv(SCHOOL_CSV, encoding='utf-8-sig')
                for _, row in df_school.iterrows():
                    if pd.notna(row.get('Institution_Keywords')) and pd.notna(row.get('å®éªŒå®¤å')):
                        keywords = str(row['Institution_Keywords']).split(';')
                        lab_name = str(row['å®éªŒå®¤å']).strip()
                        for k in keywords:
                            k_clean = k.strip().lower()
                            if k_clean:
                                if k_clean not in self.inst_map: self.inst_map[k_clean] = set()
                                self.inst_map[k_clean].add(lab_name)
                    if pd.notna(row.get('è‹±æ–‡å')):
                        people = [p.strip().lower() for p in str(row['è‹±æ–‡å']).split(';') if p.strip()]
                        self.person_rules.update(people)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½é«˜æ ¡æ•°æ®å¤±è´¥: {e}")

        # 2. åŠ è½½å…¬å¸
        try:
            if os.path.exists(COMPANY_CSV):
                df_comp = pd.read_csv(COMPANY_CSV, encoding='utf-8-sig')
                for _, row in df_comp.iterrows():
                    if pd.notna(row.get('English_Keywords')) and pd.notna(row.get('å…¬å¸å')):
                        keywords = str(row['English_Keywords']).split(';')
                        comp_name = str(row['å…¬å¸å']).strip()
                        for k in keywords:
                            k_clean = k.strip().lower()
                            if k_clean:
                                if k_clean not in self.inst_map: self.inst_map[k_clean] = set()
                                self.inst_map[k_clean].add(comp_name)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å…¬å¸æ•°æ®å¤±è´¥: {e}")

        print(f"âœ… è§„åˆ™åŠ è½½å®Œæ¯•: ç›‘æ§ {len(self.inst_map)} ä¸ªæœºæ„å…³é”®è¯")

    def check_highlight(self, authors_str):
        if not authors_str: return False
        auth_lower = authors_str.lower()
        for p in self.person_rules:
            if p in auth_lower:
                return True
        return False


import requests
import re

def fetch_full_abstract(arxiv_url):
    """ä» ArXiv abs é¡µé¢æŠ“å–å®Œæ•´çš„æ‘˜è¦"""
    try:
        # å°† /abs/ æ›¿æ¢ä¸º /abs/ (ä»¥é˜²ä¸‡ä¸€)
        resp = requests.get(arxiv_url, timeout=15, verify=False)
        if resp.status_code == 200:
            # ä½¿ç”¨æ­£åˆ™åŒ¹é… <blockquote class="abstract mathjax"> ... </blockquote>
            match = re.search(r'<blockquote class="abstract mathjax">.*?<span class="descriptor">Abstract:</span>(.*?)</blockquote>', resp.text, re.DOTALL)
            if match:
                abstract = match.group(1).strip()
                # å»é™¤å¯èƒ½çš„ HTML æ ‡ç­¾æˆ–å¤šä½™æ¢è¡Œ
                return re.sub(r'<.*?>', '', abstract).replace('\n', ' ')
    except Exception as e:
        print(f"âš ï¸ æŠ“å–æ‘˜è¦å¤±è´¥ {arxiv_url}: {e}")
    return None

# ================= 2. API è°ƒç”¨æ ¸å¿ƒ =================

# --- ä¿®æ”¹å ---
if not API_KEY:
    raise ValueError("âŒ é”™è¯¯: å¿…é¡»è®¾ç½® OPENAI_API_KEY æ‰èƒ½è¿è¡Œã€‚åœ¨ GitHub Actions ä¸­è¯·è®¾ç½® Secretsã€‚")

client = OpenAI(base_url=API_BASE, api_key=API_KEY)


def call_llm(system_prompt, user_prompt, max_tokens=5): # ä¿®æ”¹é»˜è®¤å‚æ•°
    """é€šç”¨ API è°ƒç”¨å‡½æ•°"""
    retries = 3
    for i in range(retries):
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3, # ç¨å¾®æé«˜éšæœºæ€§åˆ©äºè¯„åˆ†åŒºåˆ†
                max_tokens=max_tokens, # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
                timeout=20
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if i == retries - 1: return "NO"
            time.sleep(1)


# ================= 3. ä¸¤é˜¶æ®µæ¨ç†é€»è¾‘ =================

def filter_by_topic(raw_papers):
    """Stage 1: æ··åˆè¯é¢˜ç­›é€‰ (å…³é”®è¯ç™½åå• + å®½æ¾ LLM)"""
    print(f"\nğŸ§  [Stage 1] è¯é¢˜ç­›é€‰ (Hybrid High-Recall Mode)...")

    # === ç­–ç•¥ A: å…³é”®è¯ç™½åå• (ç›´æ¥æ”¾è¡Œï¼Œä¸æ¶ˆè€— Token) ===
    # è¿™äº›è¯å‡ºç°ä»»ä½•ä¸€ä¸ªï¼Œç»å¯¹æ˜¯å…·èº«æ™ºèƒ½/æœºå™¨äººç›¸å…³ï¼Œæ— éœ€ AI çŠ¹è±«
    WHITELIST_KEYWORDS = [
        "robot", "manipulat", "embodied", "humanoid", "locomotion",
        "navigation", "actuator", "sensorimotor", "teleoperation",
        "end-to-end control", "sim-to-real", "policy learning", "robotic",
        "dexterous", "gripper", "quadruped", "bipedal", "mobile agent", "vision-language-action"
    ]

    # === ç­–ç•¥ B: å®½æ¾çš„ LLM åˆ¤åˆ« (é’ˆå¯¹ VLA, World Model ç­‰è¾¹ç¼˜åœ°å¸¦) ===
    system_prompt = """You are a research paper filter.
Target: Papers relevant to Embodied AI, Robotics, OR their foundation technologies.

ACCEPT if the paper is about:
1. Robotics (Hardware, Control, Planning).
2. Embodied AI / Agents in environments.
3. Computer Vision (3D, Depth, Scene Understanding, Tracking).
4. AI Foundation Models (LLM/VLM) *IF* they imply reasoning, planning, or spatial understanding.
5. Reinforcement Learning.

REJECT only if completely unrelated (e.g., pure cryptography, pure database optimization, biology).

Output: "YES" or "NO"."""

    def process_one(paper):
        text_content = (paper['title'] + " " + paper['abstract']).lower()

        # 1. ç™½åå•æ£€æŸ¥ (æé€Ÿé€šé“)
        for kw in WHITELIST_KEYWORDS:
            if kw in text_content:
                # è¿™æ˜¯ä¸€ä¸ªå¼ºç›¸å…³è®ºæ–‡ï¼Œç›´æ¥ä¿ç•™ï¼Œä¸éœ€è¦é—® LLM
                return paper

        # 2. LLM æ£€æŸ¥ (å…œåº•é€šé“)
        # é’ˆå¯¹é‚£äº›æ²¡å†™ "robot" ä½†å†™äº† "world model" æˆ– "agent" çš„è®ºæ–‡
        user_prompt = f"Title: {paper['title']}\nAbstract: {paper['abstract'][:1500]}\nIs this relevant to AI/Robotics?"
        res = call_llm(system_prompt, user_prompt)

        if "YES" in res:
            return paper
        else:
            # è°ƒè¯•æ‰“å°ï¼Œçœ‹çœ‹è°è¢«æ€æ‰äº† (å¯é€‰)
            # print(f"  [ä¸¢å¼ƒ] {paper['title'][:30]}...")
            return None

    relevant_papers = []

    # ä½¿ç”¨å¹¶å‘å¤„ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = list(tqdm(executor.map(process_one, raw_papers), total=len(raw_papers), unit="paper", disable=os.environ.get('GITHUB_ACTIONS') == 'true'))

    relevant_papers = [p for p in results if p]

    print(f"âœ… è¯é¢˜ç­›é€‰å®Œæˆ: {len(raw_papers)} -> {len(relevant_papers)} ç¯‡ (å«ç™½åå•ç›´é€š)")
    return relevant_papers


def verify_affiliations(relevant_papers, dm):
    """Stage 2: æœºæ„å½’å±éªŒè¯ (è§„åˆ™+LLM æ··åˆåŒæ‰“ç‰ˆ)"""
    print(f"\nğŸ” [Stage 2] æœºæ„å½’å±éªŒè¯ (Hybrid Rules + LLM)...")

    # Prompt ç®€åŒ–ï¼Œåªä½œä¸ºå…œåº•
    system_prompt = """Check if the Candidate appears in the Author Affiliation section.
Output:
[YES] <Candidate>
[NO] <Candidate>
"""

    tasks = []

    # è°ƒè¯•ç›®æ ‡
    DEBUG_TITLE_KEY = "Collision-Free"

    paper_verified_labs = {}

    # ç»Ÿè®¡è®¡æ•°
    count_rule_pass = 0
    count_llm_check = 0

    for paper in relevant_papers:
        html_text = paper.get('html_content', '')
        if not html_text: continue
        html_lower = html_text.lower()

        # 1. é¢„å¤„ç†ï¼šæ„å»ºå…³é”®è¯æ˜ å°„
        candidate_kws = set()
        kw_to_labs_map = {}

        for kw, target_labs in dm.inst_map.items():
            if kw in html_lower:
                candidate_kws.add(kw)
                kw_to_labs_map[kw] = target_labs

        if not candidate_kws: continue

        # =========================================================
        # æ ¸å¿ƒé€»è¾‘å˜æ›´ï¼šè§„åˆ™ä¼˜å…ˆï¼ŒLLM è¾…åŠ©
        # =========================================================

        confirmed_labs_for_this_paper = set()
        llm_check_list = []  # éœ€è¦äº¤ç»™ LLM ç¡®è®¤çš„ï¼ˆåœ¨ Header æ·±å¤„çš„ï¼‰

        # å®šä¹‰ Header çš„æ ¸å¿ƒåŒºåŸŸ (å‰ 800 å­—ç¬¦é€šå¸¸åŒ…å«æ‰€æœ‰æ ¸å¿ƒå•ä½)
        # å¦‚æœå…³é”®è¯ç›´æ¥å‡ºç°åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç›´æ¥æ”¶å½•ï¼Œä¸é—® LLM äº† (çœé’± + é˜²æ¼)
        header_head = html_lower[:800]

        is_debug = DEBUG_MODE and DEBUG_TITLE_KEY in paper['title']
        if is_debug:
            print(f"\nğŸ [DEBUG] è®ºæ–‡: {paper['title']}")
            print(f"   å‘½ä¸­å…³é”®è¯: {list(candidate_kws)}")

        for kw in candidate_kws:
            # è§„åˆ™ 1: å¼ºåŒ¹é… (å¦‚æœå…³é”®è¯åœ¨å‰ 800 å­—ç¬¦ï¼Œç›´æ¥ç”±äº)
            if kw in header_head:
                labs = kw_to_labs_map[kw]
                confirmed_labs_for_this_paper.update(labs)
                count_rule_pass += 1
                if is_debug: print(f"   âœ… [è§„åˆ™é€šè¿‡] {kw} (åœ¨å¼€å¤´å‡ºç°)")
            else:
                # è§„åˆ™ 2: å¦‚æœåœ¨åé¢ï¼ŒåŠ å…¥å¾…æŸ¥åˆ—è¡¨
                llm_check_list.append(kw)

        # å¦‚æœè¿˜æœ‰éœ€è¦ LLM ç¡®è®¤çš„ï¼Œç”Ÿæˆ Task
        if llm_check_list:
            count_llm_check += 1
            candidates_str = "\n".join([f"- {c}" for c in llm_check_list])
            context = html_text[:5000]  # ç»™ LLM çœ‹é•¿ä¸€ç‚¹

            user_prompt = f"""
Paper: {paper['title']}
Candidates:
{candidates_str}

Text:
{context}

Check each candidate. Return [YES] or [NO]."""

            tasks.append({
                "paper": paper,
                "candidates": llm_check_list,  # åªä¼ éœ€è¦ç¡®è®¤çš„
                "kw_map": kw_to_labs_map,
                "current_labs": confirmed_labs_for_this_paper,  # å·²é€šè¿‡è§„åˆ™ç¡®è®¤çš„
                "prompt": user_prompt
            })
        else:
            # å¦‚æœæ‰€æœ‰å€™é€‰éƒ½åœ¨è§„åˆ™ 1 å°±é€šè¿‡äº†ï¼Œç›´æ¥ä¿å­˜
            if confirmed_labs_for_this_paper:
                url = paper['link']
                if url not in paper_verified_labs:
                    paper_verified_labs[url] = {"paper": paper, "labs": set()}
                paper_verified_labs[url]["labs"].update(confirmed_labs_for_this_paper)

    # å¤„ç† LLM ä»»åŠ¡
    if tasks:
        print(f"âš¡ {count_rule_pass} é¡¹è§„åˆ™ç›´é€šï¼Œå‰©ä½™ {len(tasks)} ä¸ªè¯·æ±‚éœ€ LLM ç¡®è®¤...")

        def process_task(task):
            is_debug = DEBUG_MODE and DEBUG_TITLE_KEY in task['paper']['title']
            confirmed = task['current_labs']  # ç»§æ‰¿è§„åˆ™ç¡®è®¤çš„

            try:
                res_str = call_llm(system_prompt, task['prompt'], max_tokens=300)

                if is_debug:
                    print(f"   ğŸ“ LLM å›å¤:\n{res_str}")

                for line in res_str.split('\n'):
                    clean_line = line.strip()
                    if clean_line.startswith("[YES]"):
                        extracted_kw = clean_line.replace("[YES]", "").strip().lower()  # å…³é”®ï¼šå¼ºåˆ¶è½¬å°å†™

                        # ä¿®å¤å¤§å°å†™åŒ¹é…é—®é¢˜
                        for cand_kw in task['candidates']:
                            # å…¨å°å†™å¯¹æ¯”
                            if cand_kw in extracted_kw or extracted_kw in cand_kw:
                                labs = task['kw_map'][cand_kw]
                                confirmed.update(labs)
                                if is_debug: print(f"   âœ… [LLMç¡®è®¤] {cand_kw}")

            except Exception as e:
                print(f"Error: {e}")

            if confirmed:
                return {"paper": task['paper'], "confirmed": confirmed}
            return None

        # æ‰§è¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            results = list(tqdm(executor.map(process_task, tasks), total=len(tasks), disable=os.environ.get('GITHUB_ACTIONS') == 'true'))

        for res in results:
            if res:
                url = res['paper']['link']
                if url not in paper_verified_labs:
                    paper_verified_labs[url] = {"paper": res['paper'], "labs": set()}
                paper_verified_labs[url]["labs"].update(res['confirmed'])

    print(f"âœ… æœ€ç»ˆä¿ç•™: {len(paper_verified_labs)} ç¯‡")
    return paper_verified_labs




def analyze_paper_quality(verified_data):
    """Stage 3: æ·±åº¦è¯„ä¼° - é€ç¯‡æ€»ç»“ + ç»Ÿä¸€æ’åºæ‰“åˆ†"""
    if not verified_data: return {}

    # --- Part A: é€ç¯‡ç”Ÿæˆæ€»ç»“ (Summary Only) ---
    print(f"\nğŸ“ [Stage 3a] æ­£åœ¨ç”Ÿæˆ {len(verified_data)} ç¯‡è®ºæ–‡çš„ç²¾ç®€æ€»ç»“...")

    # æç®€ Promptï¼Œåªè´Ÿè´£æ€»ç»“ï¼Œä¸è´Ÿè´£æ‰“åˆ†
    summary_prompt = "You are a robotics expert. Summarize this paper in ONE dense sentence (max 25 words)."

    def process_summary(item):
        paper = item['paper']
        full_abs = fetch_full_abstract(paper['link'])
        final_abstract = full_abs if full_abs else paper['abstract']
        if DEBUG_SAVE_ABSTRACT: item['abstract_full'] = final_abstract

        # åªç”Ÿæˆæ€»ç»“ï¼Œmax_tokens è®¾å°
        user_prompt = f"Title: {paper['title']}\nAbstract: {final_abstract}"
        item['ai_summary'] = call_llm(summary_prompt, user_prompt, max_tokens=60)
        return item

    # å¹¶å‘å¤„ç†æ€»ç»“
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        list(tqdm(executor.map(process_summary, verified_data.values()), total=len(verified_data), disable=os.environ.get('GITHUB_ACTIONS') == 'true'))

    # --- Part B: ç»Ÿä¸€æ’åºæ‰“åˆ† (The Secret Sauce) ---
    print(f"âš–ï¸ [Stage 3b] æ­£åœ¨å¯¹å…¨å‘˜è¿›è¡Œç«äº‰æ€§æ’åºæ‰“åˆ†...")

    # æ„é€ åˆ—è¡¨å‘ç»™ LLM
    paper_list_str = ""
    urls = list(verified_data.keys())
    for i, url in enumerate(urls):
        paper_list_str += f"[{i}] {verified_data[url]['paper']['title']}\n"

    ranking_system_prompt = """You are a judge for the "Embodied AI & Robotics" top conference.
Rank the following papers based on their RELEVANCE and CONTRIBUTION to Embodied AI (Physical World Agents).
Scoring Criteria (0-100):
High Score (90+): Real-robot results, sim-to-real transfer, VLA (Vision-Language-Action) for control, world models/planning tied to actions.
Mid Score (80-89): Vision/NLP/ML methods clearly enabling embodied tasks (perception->action, navigation, manipulation) with strong evidence of transferability.
Low Score (<80): General AI methods with unclear or indirect link to physical agents, no action/control loop, or no credible robotics pathway.
Use the full range when appropriate; avoid clustering scores. Assign a UNIQUE score to each paper. NO TIES.
Output format: [Index] Score"""

    # æ•´ä¸ªåˆ—è¡¨åªå‘ä¸€æ¬¡ API è¯·æ±‚ï¼
    rank_res = call_llm(ranking_system_prompt, paper_list_str, max_tokens=500)

    # è§£ææ’åºç»“æœ [Index] Score
    for line in rank_res.split('\n'):
        match = re.search(r"\[(\d+)\]\s*([\d\.]+)", line)
        if match:
            idx = int(match.group(1))
            score = float(match.group(2))
            if idx < len(urls):
                verified_data[urls[idx]]['ai_score'] = score

    return verified_data



# ================= 4. ä¸»ç¨‹åº =================

def main():
    # æ£€æŸ¥è¾“å…¥
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ° {INPUT_FILE}ï¼Œè¯·å…ˆè¿è¡ŒæŠ“å–è„šæœ¬ fetch_arxiv_raw.py")
        return

    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_papers = json.load(f)

    print(f"ğŸ“‚ è¯»å–åˆ° {len(raw_papers)} ç¯‡å¾…å¤„ç†è®ºæ–‡")

    # 1. åŠ è½½è§„åˆ™
    dm = DataManager()

    # 2. Stage 1: è¯é¢˜ç­›é€‰
    embodied_papers = filter_by_topic(raw_papers)

    # 3. Stage 2: æœºæ„éªŒè¯
    verified_data = verify_affiliations(embodied_papers, dm)

    # ============ [æ–°å¢] Stage 3: æ‰“åˆ†ä¸æ‘˜è¦ ============
    # åªæœ‰é€šè¿‡äº† Stage 2 çš„è®ºæ–‡æ‰ä¼šè¿›å…¥è¿™é‡Œ
    if verified_data:
        verified_data = analyze_paper_quality(verified_data)
    # ==================================================

    # 4. Stage 3: è¾“å‡ºç»“æœ
    print("\nğŸ’¾ [Final] ç”Ÿæˆæœ€ç»ˆæ•°æ®åº“...")
    final_db = {}
    count = 0

    for url, item in verified_data.items():
        paper = item['paper']
        labs = item['labs']

        # è·å– Stage 3 äº§ç”Ÿçš„æ–°å­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™ç»™é»˜è®¤å€¼
        ai_score = item.get('ai_score', 0)
        ai_summary = item.get('ai_summary', paper['abstract'][:100] + '...')

        is_highlight = dm.check_highlight(paper.get('authors_display', ''))

        paper_info = {
            "title": paper['title'],
            "url": paper['link'],
            "date": paper['date'],
            "authors_text": paper.get('authors_display', ''),
            "is_highlight": is_highlight,
            "score": item.get('ai_score', 0),
            "summary": item.get('ai_summary', ""),  # å­˜å…¥ AI ç”Ÿæˆçš„ç²¾ç®€æ‘˜è¦
        }

        # æ–¹ä¾¿è°ƒè¯•ï¼šå¦‚æœå¼€å…³æ‰“å¼€ï¼ŒæŠŠå®Œæ•´æ‘˜è¦ä¹Ÿå­˜è¿› daily_papers.json
        if DEBUG_SAVE_ABSTRACT:
            paper_info["debug_abstract"] = item.get('abstract_full', "")

        for lab in labs:
            if lab not in final_db:
                final_db[lab] = []

            # å»é‡
            if not any(p['url'] == paper_info['url'] for p in final_db[lab]):
                final_db[lab].insert(0, paper_info)
                count += 1

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_db, f, ensure_ascii=False, indent=2)

    print(f"ğŸ‰ API å¤„ç†å®Œæˆï¼")
    print(f"   å…±æ”¶å½•: {count} æ¡")
    print(f"   ç»“æœå·²ä¿å­˜: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()